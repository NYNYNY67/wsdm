hydra:
  job:
    name: causal_lm_train
  run:
    dir: data/outputs/${hydra.job.name}
  sweep:
    dir: data/outputs/${hydra.job.name}/sweep_${now:%Y%m%d_%H%M%S}
    subdir: conf_${hydra.job.id}

defaults:
  - cross_validation.yaml
  - preprocess.yaml
  - _self_

debug: false
device: cuda
model: Qwen/Qwen2.5-0.5B-Instruct

# https://huggingface.co/docs/transformers/ja/model_doc/auto#transformers.AutoModelForCausalLM.from_config.attn_implementation
attn_implementation: flash_attention_2  # default: sdpa

# quantization
quantization:
  enabled: true
  n_bit: 4
  bnb_4bit_quant_type: nf4

# lora
lora:
  lora_alpha: 32
  lora_dropout: 0.05
  r: 64
  bias: none
  target_modules:
    - o_proj
    - k_proj
    - q_proj
    - down_proj
    - gate_proj
    - up_proj
    - v_proj

# training
epochs: 10
lr: 1e-5
eval_steps: 1000
saturation_rounds: 3
validation_data_size: 200