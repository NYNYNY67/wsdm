hydra:
  job:
    name: causal_lm_infer
  run:
    dir: data/outputs/${hydra.job.name}
  sweep:
    dir: data/outputs/${hydra.job.name}/sweep_${now:%Y%m%d_%H%M%S}
    subdir: conf_${hydra.job.id}

debug: false
device: cuda
# model: data/outputs/causal_lm_train/model_fold_0
model: Qwen/Qwen2.5-0.5B-Instruct

# https://huggingface.co/docs/transformers/ja/model_doc/auto#transformers.AutoModelForCausalLM.from_config.attn_implementation
attn_implementation: flash_attention_2  # default: sdpa

# quantization
quantization:
  enabled: true
  n_bit: 4
  bnb_4bit_quant_type: nf4