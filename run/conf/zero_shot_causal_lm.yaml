hydra:
  job:
    name: zero_shot_causal_lm
  run:
    dir: data/outputs/${hydra.job.name}
  sweep:
    dir: data/outputs/${hydra.job.name}/sweep_${now:%Y%m%d_%H%M%S}
    subdir: conf_${hydra.job.id}

debug: false
device: cuda
model: Qwen/Qwen2.5-14B-Instruct
batch_size: 4

# https://huggingface.co/docs/transformers/ja/model_doc/auto#transformers.AutoModelForCausalLM.from_config.attn_implementation
attn_implementation: flash_attention_2  # default: sdpa

# quantization
quantization:
  enabled: true
  n_bit: 8
  bnb_4bit_quant_type: nf4